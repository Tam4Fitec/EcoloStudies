{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction , Normalisation , et Enregistement sur HDFS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Logo Python](python-logo-inkscape.svg \"Logo Python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import shutil\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "from shutil import copyfile\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Téléchargement à partir de sources OpenData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici les 8 sources de données à récupérer :\n",
    "\n",
    " - Population connectée au moins à un traitement secondaire des eaux usées (sdg_06_20)\n",
    " - Indice d'exploitation de l'eau, plus (WEI+) (sdg_06_60)\n",
    " - Consommation d'énergie primaire (sdg_07_10)\n",
    " - Consommation d'énergie finale (sdg_07_11)\n",
    " - Part des énergies renouvelables dans la consommation finale brute d'énergie par secteur (sdg_07_40)\n",
    " - Émissions de gaz à effet de serre (source: EEA) (sdg_13_10)\n",
    " - Intensité d´émissions de gaz à effet de serre par consommation d´énergie (sdg_13_20)\n",
    " - Part de la superficie forestière (sdg_15_10)\n",
    "\n",
    "En plus de ces sources, d'autres données ont du être récupérés :\n",
    " - Liste des pays d'Europe (code, nom, latitude, longitude)\n",
    " - Liste des Unités de nos sources de données\n",
    " \n",
    "Ces dernières données nous permettent d'enrichir nos données car les sources ne contiennent que les codes (pays et unités).\n",
    "\n",
    "Nous avons également créé un fichier avec nos propres libellés d'indicateurs pour enrichir les codes indicateurs de nos sources de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction pour le telechargement des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, filename):\n",
    "    # NOTE the stream=True parameter below\n",
    "    with requests.get(url, stream=True) as request:\n",
    "        request.encoding = 'utf-8'\n",
    "        with open(filename, 'wb') as fout:\n",
    "            for chunk in request.iter_content(chunk_size=8192): \n",
    "                # If you have chunk encoded response uncomment if\n",
    "                # and set chunk_size parameter to None.\n",
    "                #if chunk: \n",
    "                fout.write(chunk)\n",
    "    if not request.ok:\n",
    "            print(f'download failed for {url}')\n",
    "            print(f'reason: {request.reason}')\n",
    "            return\n",
    "    else:\n",
    "        print(f'download succeded: {request.ok}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupération des différents fichiers à partir des sources de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download succeded: True\n",
      "download succeded: True\n",
      "download succeded: True\n",
      "download succeded: True\n",
      "download succeded: True\n",
      "download succeded: True\n",
      "download succeded: True\n",
      "download succeded: True\n",
      "download succeded: True\n",
      "download succeded: True\n"
     ]
    }
   ],
   "source": [
    "#Liste des pays d'Europe\n",
    "urlPays = r'https://gist.githubusercontent.com/tadast/8827699/raw/f5cac3d42d16b78348610fc4ec301e9234f82821/countries_codes_and_coordinates.csv'\n",
    "filePays = 'countries_codes_and_coordinates.csv'\n",
    "download_file(urlPays, filePays)\n",
    "\n",
    "#Liste des Unités\n",
    "urlUnit = r'http://dd.eionet.europa.eu/vocabulary/eurostat/unit/csv'\n",
    "fileUnit = 'unit.csv'\n",
    "download_file(urlUnit, fileUnit)\n",
    "\n",
    "#Population connectée au moins à un traitement secondaire des eaux usées (sdg_06_20)\n",
    "url6_20 = r'https://ec.europa.eu/eurostat/api/dissemination/sdmx/2.1/data/SDG_06_20/?format=sdmx_2.0_generic&compressed=true\"'\n",
    "file6_20 = 'sdg_06_20.xml'\n",
    "download_file(url6_20, file6_20)\n",
    "\n",
    "#Indice d'exploitation de l'eau, plus (WEI+) (sdg_06_60)\n",
    "url6_60 = r'https://ec.europa.eu/eurostat/api/dissemination/sdmx/2.1/data/SDG_06_60/?format=sdmx_2.0_generic&compressed=true\"'\n",
    "file6_60 = 'sdg_06_60.xml'\n",
    "download_file(url6_60, file6_60)\n",
    "\n",
    "#Consommation d'énergie primaire (sdg_07_10)\n",
    "url7_10 = r'https://ec.europa.eu/eurostat/api/dissemination/sdmx/2.1/data/SDG_07_10/?format=TSV&compressed=true\"'\n",
    "file7_10 = 'sdg_07_10.tsv'\n",
    "download_file(url7_10, file7_10)\n",
    "\n",
    "#Consommation d'énergie finale (sdg_07_11)\n",
    "url7_11 = r'https://ec.europa.eu/eurostat/api/dissemination/sdmx/2.1/data/SDG_07_11/?format=TSV&compressed=true\"'\n",
    "file7_11 = 'sdg_07_11.tsv'\n",
    "download_file(url7_11, file7_11)\n",
    "\n",
    "#Part des énergies renouvelables dans la consommation finale brute d'énergie par secteur (sdg_07_40)\n",
    "url7_40 = r'https://ec.europa.eu/eurostat/api/dissemination/sdmx/2.1/data/SDG_07_40/?format=TSV&compressed=true\"'\n",
    "file7_40 = 'sdg_07_40.tsv'\n",
    "download_file(url7_40, file7_40)\n",
    "\n",
    "#Émissions de gaz à effet de serre (source: EEA) (sdg_13_10)\n",
    "url13_10 = r'https://ec.europa.eu/eurostat/api/dissemination/sdmx/2.1/data/SDG_13_10/?format=JSON&lang=fr'\n",
    "file13_10 = 'sdg_13_10.json'\n",
    "download_file(url13_10, file13_10)\n",
    "\n",
    "#Intensité d´émissions de gaz à effet de serre par consommation d´énergie (sdg_13_20)\n",
    "url13_20 = r'https://ec.europa.eu/eurostat/api/dissemination/sdmx/2.1/data/SDG_13_20/?format=TSV&compressed=true\"'\n",
    "file13_20 = 'sdg_13_20.tsv'\n",
    "download_file(url13_20, file13_20)\n",
    "\n",
    "#Part de la superficie forestière (sdg_15_10)\n",
    "url15_10 = r'https://ec.europa.eu/eurostat/api/dissemination/sdmx/2.1/data/SDG_15_10/?format=TSV&compressed=true\"'\n",
    "file15_10 = 'sdg_15_10.tsv'\n",
    "download_file(url15_10, file15_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating indicator file in CSV indicateur.csv tab-delimited file...\n",
      "File indicateur.csv created.\n"
     ]
    }
   ],
   "source": [
    "#Création du fichier des Indicateurs\n",
    "\n",
    "def createIndicateur(fichier):\n",
    "    print(\"Creating indicator file in CSV \" + fichier + \" tab-delimited file...\")\n",
    "    with open(fichier, 'w') as fout:\n",
    "        lignes = 'Indicateur\\tLibelle\\n'\n",
    "        lignes = lignes + 'GHG_I90\\tIndice d\\'émissions de gaz à effet de serre (en équivalent CO2), année de base 1990\\n'\n",
    "        lignes = lignes + 'GHG_T_HAB\\tIndice d\\'émissions de gaz à effet de serre - tonnes par tête\\n'\n",
    "        lignes = lignes + 'REN\\tSources d\\'énergie renouvelable\\n'\n",
    "        lignes = lignes + 'REN_ELC\\tSources d\\'énergie renouvelable dans l\\'électricité\\n'\n",
    "        lignes = lignes + 'REN_HEAT_CL\\tSources d\\'énergie renouvelable dans le chauffage et le refroidissement\\n'\n",
    "        lignes = lignes + 'REN_TRA\\tSources d\\'énergie renouvelable dans les transports\\n'\n",
    "        lignes = lignes + 'LCC1\\tForêt\\n'\n",
    "        lignes = lignes + 'LCC1_2\\tForêt et autres terres boisées\\n'\n",
    "        lignes = lignes + 'LCC2\\tAutres terres boisées\\n'\n",
    "        lignes = lignes + 'sdg_06_20\\tPopulation connectée au moins à un traitement secondaire des eaux usées\\n'\n",
    "        lignes = lignes + 'sdg_06_60\\tIndice d\\'exploitation de l\\'eau, plus (WEI+)\\n'\n",
    "        lignes = lignes + 'sdg_07_10\\tConsommation d\\'énergie primaire\\n'\n",
    "        lignes = lignes + 'sdg_07_11\\tConsommation d\\'énergie finale\\n'\n",
    "        lignes = lignes + 'sdg_13_20\\tIntensité d´émissions de gaz à effet de serre par consommation d´énergie\\n'\n",
    "        fout.write(lignes)\n",
    "    print(\"File \" + fichier + \" created.\")\n",
    "    return fichier\n",
    "    \n",
    "fichierIndicOutput = createIndicateur('indicateur.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Normalisation des fichiers extraits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalisation du fichier Unit\n",
    "def sedFichierUnit(nomFichier):\n",
    "    fichierOutput = 'output_' + nomFichier\n",
    "    os.system('cut -d \",\" -f2-6 ' + nomFichier + ' > ' + fichierOutput)\n",
    "    #print('sed -i -r \\'s/\\\",\\\"/\\\"\\t\\\"/g\\' ' + fichierOutput)\n",
    "    os.system('sed -i -r \\'s/\\\",\\\"/\\\"\\t\\\"/g\\' ' + fichierOutput)\n",
    "    #print('sed -i -r \\'s/\"//g\\' ' + fichierOutput)\n",
    "    os.system('sed -i -r \\'s/\"//g\\' ' + fichierOutput)\n",
    "    return fichierOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fichierUnitOutput = sedFichierUnit(fileUnit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalisation du fichier Pays\n",
    "def sedFichierPays(nomFichier):\n",
    "    fichierOutput = 'output_' + nomFichier\n",
    "    lignesSup = '\\nUnion européenne (agrégat variable en fonction du contexte)\\tEU_V\\tEU_V\\t9990\\t0\\t0\\n'\n",
    "    lignesSup = lignesSup + 'Union européenne - 27 pays (à partir de 2020)\\tEU27_2020\\tEU27_2020\\t9991\\t0\\t0\\n'\n",
    "    lignesSup = lignesSup + 'Union européenne - 28 pays (2013-2020)\\tEU28\\tEU28\\t9992\\t0\\t0\\n'\n",
    "    lignesSup = lignesSup + 'Union européenne - 27 pays (2007-2013)\\tEU27_2007\\tEU27_2007\\t9993\\t0\\t0\\n'\n",
    "    lignesSup = lignesSup + 'Zone euro - 19 pays (à partir de 2015)\\tEA19\\tEA19\\t9994\\t0\\t0\\n'\n",
    "    copyfile(nomFichier, fichierOutput)\n",
    "    os.system('sed -i -r \\'s/\\\",\\\"/\\\"\\t\\\"/g\\' ' + fichierOutput)\n",
    "    os.system('sed -i -r \\'s/\\\", \\\"/\\\"\\t\\\"/g\\' ' + fichierOutput)\n",
    "    os.system('sed -i -r \\'s/\"//g\\' ' + fichierOutput)\n",
    "    with open(fichierOutput, 'a') as f_object:\n",
    "        f_object.write(lignesSup)\n",
    "    return fichierOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fichierPaysOutput = sedFichierPays(filePays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation des fichiers CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalisation des fichiers CSV avec 4 dimensions : frequence, unité, pays, année\n",
    "def conversionCSV3Param(fichier):\n",
    "    inputPath = fichier\n",
    "    outputPath = \"temp_\" + inputPath\n",
    "    outputPath2 = \"output_\" + inputPath\n",
    "    print(\"Converting CSV \" + inputPath + \" to tab-delimited file...\")\n",
    "    with open(inputPath) as fin, open(outputPath, 'w') as fout:\n",
    "        for line in fin:\n",
    "            fout.write(line.replace(',', '\\t').replace('geo'\"\\\\\"'TIME_PERIOD', 'pays\\tannee\\tvaleur'))\n",
    "\n",
    "    first_ligne = True\n",
    "    with open(outputPath) as fin, open(outputPath2, 'w') as fout:\n",
    "        for line in fin:\n",
    "            if (first_ligne):\n",
    "                #print('First line : ' + line)\n",
    "                first_data = line.split('\\t')\n",
    "                unit_label = first_data[1].rstrip('\\n')\n",
    "                #print('Unit : ' + unit)\n",
    "                pays_label = first_data[2].rstrip('\\n')\n",
    "                #print('pays : ' + pays)\n",
    "                annee_label = first_data[3].rstrip('\\n')\n",
    "                #print('value : ' + value)\n",
    "                valeur_label = first_data[4].rstrip('\\n')\n",
    "\n",
    "                indicateur_label = \"indicateur\"\n",
    "                region_label = \"region\"\n",
    "\n",
    "                #print('annee : ' + annee)\n",
    "                listeAnnees = []\n",
    "                for i in range(5, len(first_data)):\n",
    "                    #print(first_data[i])\n",
    "                    listeAnnees.append(first_data[i].strip().rstrip('\\t').rstrip('\\n'))\n",
    "                output_line = pays_label + '\\t' + indicateur_label + '\\t' + unit_label + '\\t' + region_label + '\\t' + annee_label + '\\t' + valeur_label +'\\n'\n",
    "                #fout.write(output_line)\n",
    "                first_ligne = False\n",
    "            else:\n",
    "                #print(len(listeAnnees))\n",
    "                #print('Line : ' + line)\n",
    "                line_data = line.split('\\t')\n",
    "                \n",
    "                unit = line_data[1].strip().rstrip('\\n')\n",
    "\n",
    "                indicateur = inputPath.strip().rstrip('.tsv')\n",
    "\n",
    "                region = \"\"\n",
    "\n",
    "                #print('Unit : ' + unit)\n",
    "                pays = line_data[2].strip().rstrip('\\n')\n",
    "\n",
    "                listeValeurs = []\n",
    "\n",
    "                for i in range(3, len(line_data)):\n",
    "                    #print(first_data[i])\n",
    "                    listeValeurs.append(line_data[i].strip().rstrip('\\t').rstrip('\\n'))\n",
    "\n",
    "                for i in range(0, len(listeValeurs)):\n",
    "                    output_line = pays + '\\t' + indicateur + '\\t' + unit + '\\t' + region + '\\t' + listeAnnees[i] + '\\t' + listeValeurs[i] +'\\n'\n",
    "                    fout.write(output_line)\n",
    "\n",
    "    print(\"Conversion complete, file \" + outputPath2 + \" created.\")\n",
    "    return outputPath2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting CSV sdg_07_10.tsv to tab-delimited file...\n",
      "Conversion complete, file output_sdg_07_10.tsv created.\n",
      "Converting CSV sdg_07_11.tsv to tab-delimited file...\n",
      "Conversion complete, file output_sdg_07_11.tsv created.\n",
      "Converting CSV sdg_13_20.tsv to tab-delimited file...\n",
      "Conversion complete, file output_sdg_13_20.tsv created.\n"
     ]
    }
   ],
   "source": [
    "fichier7_10Output = conversionCSV3Param(file7_10)\n",
    "fichier7_11Output = conversionCSV3Param(file7_11)\n",
    "fichier13_20Output = conversionCSV3Param(file13_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalisation des fichiers CSV avec 5 dimensions\n",
    "def conversionCSV4Param(fichier):\n",
    "    inputPath = fichier\n",
    "    outputPath = \"temp_\" + inputPath\n",
    "    outputPath2 = \"output_\" + inputPath\n",
    "    print(\"Converting CSV \" + inputPath + \" to tab-delimited file...\")\n",
    "    with open(inputPath) as fin, open(outputPath, 'w') as fout:\n",
    "        for line in fin:\n",
    "            fout.write(line.replace(': ', '').replace(',', '\\t').replace('geo'\"\\\\\"'TIME_PERIOD', 'pays\\tannee\\tvaleur'))\n",
    "\n",
    "    first_ligne = True\n",
    "    with open(outputPath) as fin, open(outputPath2, 'w') as fout:\n",
    "        for line in fin:\n",
    "            if (first_ligne):\n",
    "                #print('First line : ' + line)\n",
    "                first_data = line.split('\\t')\n",
    "                indicateur_label = first_data[1].rstrip('\\n')\n",
    "\n",
    "                unit_label = first_data[2].rstrip('\\n')\n",
    "                #print('Unit : ' + unit)\n",
    "                pays_label = first_data[3].rstrip('\\n')\n",
    "                #print('pays : ' + pays)\n",
    "                annee_label = first_data[4].rstrip('\\n')\n",
    "                #print('value : ' + value)\n",
    "                valeur_label = first_data[5].rstrip('\\n')\n",
    "\n",
    "                region_label = \"region\"\n",
    "\n",
    "                #print('annee : ' + annee)\n",
    "                listeAnnees = []\n",
    "                for i in range(6, len(first_data)):\n",
    "                    #print(first_data[i])\n",
    "                    listeAnnees.append(first_data[i].strip().rstrip('\\t').rstrip('\\n'))\n",
    "                output_line = pays_label + '\\t' + indicateur_label + '\\t' + unit_label + '\\t' + region_label + '\\t' + annee_label + '\\t' + valeur_label +'\\n'\n",
    "                #fout.write(output_line)\n",
    "                first_ligne = False\n",
    "            else:\n",
    "                #print(len(listeAnnees))\n",
    "                #print('Line : ' + line)\n",
    "                line_data = line.split('\\t')\n",
    "                \n",
    "                indicateur = line_data[1].strip().rstrip('\\n')\n",
    "\n",
    "                unit = line_data[2].strip().rstrip('\\n')\n",
    "\n",
    "                region = \"\"\n",
    "\n",
    "                #print('Unit : ' + unit)\n",
    "                pays = line_data[3].strip().rstrip('\\n')\n",
    "\n",
    "                listeValeurs = []\n",
    "\n",
    "                for i in range(4, len(line_data)):\n",
    "                    #print(first_data[i])\n",
    "                    listeValeurs.append(line_data[i].strip().rstrip(' u').rstrip(' p').rstrip('\\t').rstrip('\\n'))\n",
    "\n",
    "                for i in range(0, len(listeValeurs)):\n",
    "                    output_line = pays + '\\t' + indicateur + '\\t' + unit + '\\t' + region + '\\t' + listeAnnees[i] + '\\t' + listeValeurs[i] +'\\n'\n",
    "                    fout.write(output_line)\n",
    "\n",
    "    print(\"Conversion complete, file \" + outputPath2 + \" created.\")\n",
    "    return outputPath2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting CSV sdg_07_40.tsv to tab-delimited file...\n",
      "Conversion complete, file output_sdg_07_40.tsv created.\n"
     ]
    }
   ],
   "source": [
    "fichier7_40Output = conversionCSV4Param(file7_40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalisation des fichiers CSV avec 5 dimensions\n",
    "def conversionCSV5Param(fichier):\n",
    "    inputPath = fichier\n",
    "    outputPath = \"temp_\" + inputPath\n",
    "    outputPath2 = \"output_\" + inputPath\n",
    "    print(\"Converting CSV \" + inputPath + \" to tab-delimited file...\")\n",
    "    with open(inputPath) as fin, open(outputPath, 'w') as fout:\n",
    "        for line in fin:\n",
    "            fout.write(line.replace(': ', '').replace(',', '\\t').replace('geo'\"\\\\\"'TIME_PERIOD', 'pays\\tannee\\tvaleur'))\n",
    "\n",
    "    first_ligne = True\n",
    "    with open(outputPath) as fin, open(outputPath2, 'w') as fout:\n",
    "        for line in fin:\n",
    "            if (first_ligne):\n",
    "                #print('First line : ' + line)\n",
    "                first_data = line.split('\\t')\n",
    "                unit_label = first_data[1].rstrip('\\n')\n",
    "                indicateur_label = first_data[2].rstrip('\\n')\n",
    "                #print('Unit : ' + unit)\n",
    "                pays_label = first_data[3].rstrip('\\n')\n",
    "                #print('pays : ' + pays)\n",
    "                annee_label = first_data[4].rstrip('\\n')\n",
    "                #print('value : ' + value)\n",
    "                valeur_label = first_data[5].rstrip('\\n')\n",
    "\n",
    "                region_label = \"region\"\n",
    "\n",
    "                #print('annee : ' + annee)\n",
    "                listeAnnees = []\n",
    "                for i in range(6, len(first_data)):\n",
    "                    #print(first_data[i])\n",
    "                    listeAnnees.append(first_data[i].strip().rstrip('\\t').rstrip('\\n'))\n",
    "                output_line = pays_label + '\\t' + indicateur_label + '\\t' + unit_label + '\\t' + region_label + '\\t' + annee_label + '\\t' + valeur_label +'\\n'\n",
    "                #fout.write(output_line)\n",
    "                first_ligne = False\n",
    "            else:\n",
    "                #print(len(listeAnnees))\n",
    "                #print('Line : ' + line)\n",
    "                line_data = line.split('\\t')\n",
    "                \n",
    "                unit = line_data[1].strip().rstrip('\\n')\n",
    "                indicateur = line_data[2].strip().rstrip('\\n')\n",
    "\n",
    "                region = \"\"\n",
    "\n",
    "                #print('Unit : ' + unit)\n",
    "                pays = line_data[3].strip().rstrip('\\n')\n",
    "\n",
    "                listeValeurs = []\n",
    "\n",
    "                for i in range(4, len(line_data)):\n",
    "                    #print(first_data[i])\n",
    "                    listeValeurs.append(line_data[i].strip().rstrip(' u').rstrip(' p').rstrip('\\t').rstrip('\\n'))\n",
    "\n",
    "                for i in range(0, len(listeValeurs)):\n",
    "                    output_line = pays + '\\t' + indicateur + '\\t' + unit + '\\t' + region + '\\t' + listeAnnees[i] + '\\t' + listeValeurs[i] +'\\n'\n",
    "                    fout.write(output_line)\n",
    "\n",
    "    print(\"Conversion complete, file \" + outputPath2 + \" created.\")\n",
    "    return outputPath2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting CSV sdg_15_10.tsv to tab-delimited file...\n",
      "Conversion complete, file output_sdg_15_10.tsv created.\n"
     ]
    }
   ],
   "source": [
    "fichier15_10Output = conversionCSV5Param(file15_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation des fichiers JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversionJSON(fichier):\n",
    "    inputPath = fichier\n",
    "    outputPath = \"output_\" + inputPath\n",
    "    with open(inputPath) as fin, open(outputPath,'w') as fout:\n",
    "        print(\"Converting JSON \" + inputPath + \" file...\")\n",
    "        data = json.load(fin)\n",
    "        #print(data)\n",
    "        #result = json_normalize(data, 'value')\n",
    "        list_valeurs = []\n",
    "        for key, value in data['value'].items():\n",
    "            list_valeurs.append(value)\n",
    "\n",
    "        list_ids = data['id']\n",
    "        #print(list_ids)\n",
    "\n",
    "        #freq_id = list_ids[0]\n",
    "        indic_id = list_ids[1]\n",
    "        geo_id = list_ids[2]\n",
    "        time_id = list_ids[3]\n",
    "\n",
    "        list_dimensions = data['dimension']\n",
    "        #list_dim_freq = list_dimensions[freq_id]['category']['index']\n",
    "        #for key in list_dim_freq.keys(): print(key)\n",
    "        list_dim_indic = list_dimensions[indic_id]['category']['index']\n",
    "        #for key in list_dim_indic.keys(): print(key)\n",
    "\n",
    "        list_dim_geo = []\n",
    "        for key, value in list_dimensions[geo_id]['category']['index'].items():\n",
    "            list_dim_geo.append(key)\n",
    "        list_dim_geo.sort()\n",
    "        #for key in list_dim_geo.keys(): print(key)\n",
    "        list_dim_time = list_dimensions[time_id]['category']['index']\n",
    "        #for key in list_dim_time.keys(): print(key)\n",
    "        \n",
    "        unit = \"\"\n",
    "        region = \"\"\n",
    "        output_line = \"\"\n",
    "        cpt = 0\n",
    "        for key_indic in list_dim_indic.keys() :\n",
    "            for i in range (0, len(list_dim_geo)):\n",
    "                for key_annee in list_dim_time.keys() :\n",
    "                    if(cpt == 0):\n",
    "                        output_line = '{\"pays\" : \"' + list_dim_geo[i] + '\", \"indic\" : \"' + key_indic + '\", \"unit\" : \"' + unit + '\", \"region\" : \"' + region + '\", \"annee\" : ' + key_annee + ', \"valeur\" : ' + str(list_valeurs[cpt]) + '}'\n",
    "                    else:    \n",
    "                        output_line = output_line + ',{\"pays\" : \"' + list_dim_geo[i] + '\", \"indic\" : \"' + key_indic + '\", \"unit\" : \"' + unit + '\", \"region\" : \"' + region + '\", \"annee\" : ' + key_annee + ', \"valeur\" : ' + str(list_valeurs[cpt]) + '}'\n",
    "                    cpt = cpt + 1\n",
    "        \n",
    "        output_line = '{ \"donnees\" : [' + output_line + ']}'\n",
    "        fout.write(output_line)\n",
    "        print(\"Conversion complete, file \" + outputPath + \" created.\")\n",
    "        return outputPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting JSON sdg_13_10.json file...\n",
      "Conversion complete, file output_sdg_13_10.json created.\n"
     ]
    }
   ],
   "source": [
    "fichier13_10Output = conversionJSON(file13_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation des fichiers XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformationXML(filename):\n",
    "    os.system(\"sed -i -r -e 's/g://g' -e 's/m://g' \" + filename)\n",
    "    os.system(\"sed -i -r -e 's/<GenericData xmlns.*><Header>/<GenericData><Header>/' \" + filename)\n",
    "    return XMLToCSV(filename)\n",
    "\n",
    "\n",
    "def XMLToCSV(filename):\n",
    "    tree = ET.parse(filename)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    for dataset in root.findall('DataSet'):\n",
    "        default_indic = dataset.find('KeyFamilyRef').text\n",
    "    indic = default_indic.lower()\n",
    "\n",
    "    # open a file for writing\n",
    "    newfilename = \"output_\" + filename[:-3] + \"csv\"\n",
    "    Ecolo_data = open(newfilename, 'w')\n",
    "\n",
    "    # create the csv writer object\n",
    "    csvwriter = csv.writer(Ecolo_data,  delimiter='\\t')\n",
    "\n",
    "    tree_s = dataset.findall('Series')\n",
    "    for s in tree_s:\n",
    "        s_data = []\n",
    "        s_data_all = []\n",
    "        tree_sk = s.findall('SeriesKey')\n",
    "        for sk in tree_sk :\n",
    "            for v in sk.iter('Value'):\n",
    "                if v.attrib['concept'] == 'geo':\n",
    "                    geo = v.get('value')\n",
    "                    s_data.append(geo)\n",
    "                    s_data.append(indic)\n",
    "                if v.attrib['concept'] == 'unit':\n",
    "                    unit = v.get('value')\n",
    "                    s_data.append(unit)\n",
    "        s_data.append(\"\")\n",
    "\n",
    "        tree_obs = s.findall('Obs')\n",
    "        for o in tree_obs:\n",
    "            s_data_all = s_data[:]\n",
    "            annee = o.find('Time').text\n",
    "            obsval = o.find('ObsValue').get('value')\n",
    "            s_data_all.append(annee)\n",
    "            s_data_all.append(obsval)\n",
    "            csvwriter.writerow(s_data_all)\n",
    "    \n",
    "    Ecolo_data.close()\n",
    "    return newfilename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fichier6_20Output = transformationXML(file6_20)\n",
    "fichier6_60Output = transformationXML(file6_60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Enregistrement sur HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Logo Hadoop](2500px-Hadoop_logo_new.svg.png \"Logo Hadoop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du répertoire de sauvegarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createHDFSFolder(hdfs_path, hdfs_host = r\"http://localhost:50070/webhdfs/v1\"):\n",
    "    # Create a folder to store data in HDFS\n",
    "    r = requests.put(hdfs_host + hdfs_path, params=r'user.name=cloudera&op=MKDIRS')\n",
    "    if not r.ok:\n",
    "        print(f'Failed to create folder {hdfs_path}')\n",
    "        print(f'Reason: {r.reason}')\n",
    "        return\n",
    "    else:\n",
    "        print(f'create path: {r.ok}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create path: True\n"
     ]
    }
   ],
   "source": [
    "hdfs_path = \"/user/cloudera/DevDurable/\"\n",
    "createHDFSFolder(hdfs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Envoi des fichiers sur HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file(filename, hdfs_path, hdfs_name, hdfs_host = r\"http://localhost:50070/webhdfs/v1\"):\n",
    "    \n",
    "    # Request path for file PUT\n",
    "    r = requests.put(hdfs_host + hdfs_path, params=r'user.name=cloudera&op=CREATE', allow_redirects=False)\n",
    "    \n",
    "    # Parse path for file PUT\n",
    "    reply_path = r.headers['Location'].replace('quickstart.cloudera', 'localhost').split('?')\n",
    "    \n",
    "    print(reply_path)\n",
    "    \n",
    "    with open(filename) as fin:\n",
    "        # upload to hdfs\n",
    "        to_hdfs = requests.put(reply_path[0] + hdfs_name, params=reply_path[1], data=fin.read().encode('utf-8'), stream=True)     \n",
    "\n",
    "    if not to_hdfs.ok:\n",
    "            print(f'hdfs upload failed for {hdfs_name}')\n",
    "            print(f'reason: {to_hdfs.reason}')\n",
    "            return\n",
    "    else:\n",
    "        print(f'hdfs upload succeded: {to_hdfs.ok}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://localhost:50075/webhdfs/v1/user/cloudera/DevDurable/', 'op=CREATE&user.name=cloudera&namenoderpcaddress=localhost:8020&overwrite=false']\n",
      "hdfs upload succeded: True\n",
      "['http://localhost:50075/webhdfs/v1/user/cloudera/DevDurable/', 'op=CREATE&user.name=cloudera&namenoderpcaddress=localhost:8020&overwrite=false']\n",
      "hdfs upload succeded: True\n",
      "['http://localhost:50075/webhdfs/v1/user/cloudera/DevDurable/', 'op=CREATE&user.name=cloudera&namenoderpcaddress=localhost:8020&overwrite=false']\n",
      "hdfs upload succeded: True\n",
      "['http://localhost:50075/webhdfs/v1/user/cloudera/DevDurable/', 'op=CREATE&user.name=cloudera&namenoderpcaddress=localhost:8020&overwrite=false']\n",
      "hdfs upload succeded: True\n",
      "['http://localhost:50075/webhdfs/v1/user/cloudera/DevDurable/', 'op=CREATE&user.name=cloudera&namenoderpcaddress=localhost:8020&overwrite=false']\n",
      "hdfs upload succeded: True\n",
      "['http://localhost:50075/webhdfs/v1/user/cloudera/DevDurable/', 'op=CREATE&user.name=cloudera&namenoderpcaddress=localhost:8020&overwrite=false']\n",
      "hdfs upload succeded: True\n",
      "['http://localhost:50075/webhdfs/v1/user/cloudera/DevDurable/', 'op=CREATE&user.name=cloudera&namenoderpcaddress=localhost:8020&overwrite=false']\n",
      "hdfs upload succeded: True\n",
      "['http://localhost:50075/webhdfs/v1/user/cloudera/DevDurable/', 'op=CREATE&user.name=cloudera&namenoderpcaddress=localhost:8020&overwrite=false']\n",
      "hdfs upload succeded: True\n",
      "['http://localhost:50075/webhdfs/v1/user/cloudera/DevDurable/', 'op=CREATE&user.name=cloudera&namenoderpcaddress=localhost:8020&overwrite=false']\n",
      "hdfs upload succeded: True\n",
      "['http://localhost:50075/webhdfs/v1/user/cloudera/DevDurable/', 'op=CREATE&user.name=cloudera&namenoderpcaddress=localhost:8020&overwrite=false']\n",
      "hdfs upload succeded: True\n",
      "['http://localhost:50075/webhdfs/v1/user/cloudera/DevDurable/', 'op=CREATE&user.name=cloudera&namenoderpcaddress=localhost:8020&overwrite=false']\n",
      "hdfs upload succeded: True\n"
     ]
    }
   ],
   "source": [
    "#Upload de tous les fichiers\n",
    "\n",
    "upload_file(fichierPaysOutput, hdfs_path, fichierPaysOutput)\n",
    "upload_file(fichierUnitOutput, hdfs_path, fichierUnitOutput)\n",
    "upload_file(fichierIndicOutput, hdfs_path, fichierIndicOutput)\n",
    "upload_file(fichier6_20Output, hdfs_path, fichier6_20Output)\n",
    "upload_file(fichier6_60Output, hdfs_path, fichier6_60Output)\n",
    "upload_file(fichier7_10Output, hdfs_path, fichier7_10Output)\n",
    "upload_file(fichier7_11Output, hdfs_path, fichier7_11Output)\n",
    "upload_file(fichier7_40Output, hdfs_path, fichier7_40Output)\n",
    "upload_file(fichier13_10Output, hdfs_path, fichier13_10Output)\n",
    "upload_file(fichier13_20Output, hdfs_path, fichier13_20Output)\n",
    "upload_file(fichier15_10Output, hdfs_path, fichier15_10Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
